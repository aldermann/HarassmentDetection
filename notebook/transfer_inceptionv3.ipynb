{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_inceptionv3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Qm6iWVHdJxbS","colab_type":"code","outputId":"131ac8dd-0762-4610-f6ee-9280a757b252","executionInfo":{"status":"ok","timestamp":1557203535518,"user_tz":-420,"elapsed":4361,"user":{"displayName":"Long Vu","photoUrl":"https://lh5.googleusercontent.com/-oL_u8wVxMmU/AAAAAAAAAAI/AAAAAAAAABI/MPByVuZoJO0/s64/photo.jpg","userId":"11726823621970821777"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wb7uqAnyKLuN","colab_type":"code","colab":{}},"source":["from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing import image\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import backend as K\n","from keras.callbacks import ModelCheckpoint\n","from keras.callbacks import TensorBoard\n","import os.path\n","\n","# create the base pre-trained model\n","base_model = InceptionV3(weights='imagenet', include_top=False)\n","\n","# dimensions of our images.\n","#Inception input size\n","img_width, img_height = 299, 299\n","\n","path = '/gdrive/My Drive/DA-20182/model/inceptionv3'\n","\n","top_layers_checkpoint_path = os.path.join(path, 'cp.top.best.hdf5')\n","fine_tuned_checkpoint_path = os.path.join(path, 'cp.fine_tuned.best.hdf5')\n","new_extended_inception_weights = os.path.join(path, 'final_weights.hdf5')\n","\n","train_data_dir = '/gdrive/My Drive/DA-20182/forest_datasets/image/train'\n","# validation_data_dir = '/tmp/data/validation'\n","\n","nb_train_samples = 9173\n","nb_validation_samples = 800\n","\n","top_epochs = 50\n","fit_epochs = 50\n","\n","batch_size = 128\n","\n","# add a global spatial average pooling layer\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","# let's add a fully-connected layer\n","x = Dense(1024, activation='relu')(x)\n","# and a logistic layer -- we have 2 classes\n","predictions = Dense(2, activation='softmax')(x)\n","\n","# this is the model we will train\n","model = Model(input=base_model.input, output=predictions)\n","\n","if os.path.exists(top_layers_checkpoint_path):\n","\tmodel.load_weights(top_layers_checkpoint_path)\n","\tprint (\"Checkpoint '\" + top_layers_checkpoint_path + \"' loaded.\")\n","\n","# first: train only the top layers (which were randomly initialized)\n","# i.e. freeze all convolutional InceptionV3 layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# compile the model (should be done *after* setting layers to non-trainable)\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], )\n","\n","# prepare data augmentation configuration\n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","test_datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","\n","#Save the model after every epoch.\n","mc_top = ModelCheckpoint(top_layers_checkpoint_path, monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","\n","#Save the TensorBoard logs.\n","tb = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=True)\n","\n","# train the model on the new data for a few epochs\n","#model.fit_generator(...)\n","\n","model.fit_generator(\n","    train_generator,\n","    samples_per_epoch=nb_train_samples // batch_size,\n","    nb_epoch=top_epochs,\n","    validation_data=validation_generator,\n","    nb_val_samples=nb_validation_samples // batch_size,\n","    callbacks=[mc_top, tb])\n","\n","# at this point, the top layers are well trained and we can start fine-tuning\n","# convolutional layers from inception V3. We will freeze the bottom N layers\n","# and train the remaining top layers.\n","\n","# let's visualize layer names and layer indices to see how many layers\n","# we should freeze:\n","for i, layer in enumerate(base_model.layers):\n","   print(i, layer.name)\n","\n","\n","#Save the model after every epoch.\n","mc_fit = ModelCheckpoint(fine_tuned_checkpoint_path, monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","\n","\n","if os.path.exists(fine_tuned_checkpoint_path):\n","\tmodel.load_weights(fine_tuned_checkpoint_path)\n","\tprint (\"Checkpoint '\" + fine_tuned_checkpoint_path + \"' loaded.\")\n","\n","# we chose to train the top 2 inception blocks, i.e. we will freeze\n","# the first 172 layers and unfreeze the rest:\n","for layer in model.layers[:280]:\n","   layer.trainable = False\n","for layer in model.layers[280:]:\n","   layer.trainable = True\n","\n","# we need to recompile the model for these modifications to take effect\n","# we use SGD with a low learning rate\n","from keras.optimizers import SGD\n","model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# we train our model again (this time fine-tuning the top 2 inception blocks\n","# alongside the top Dense layers\n","#model.fit_generator(...)\n","\n","model.fit_generator(\n","    train_generator,\n","    samples_per_epoch=nb_train_samples // batch_size,\n","    nb_epoch=fit_epochs,\n","    validation_data=validation_generator,\n","    nb_val_samples=nb_validation_samples // batch_size,\n","    callbacks=[mc_fit, tb])\n","\n","model.save_weights(new_extended_inception_weights)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PgI6-OPMOpO0","colab_type":"code","colab":{}},"source":["inceptionv3 = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n","# inceptionv3.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OqdOyqUKnCiW","colab_type":"code","colab":{}},"source":["inceptionv3.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NXbNkCUBb9qG","colab_type":"code","colab":{}},"source":["test = inceptionv3\n","test.layers.pop()\n","test.outputs = [test.layers[-1].output]\n","test.layers[-1].outbound_nodes = []\n","x = test.output\n","# let's add a fully-connected layer\n","x = Dense(1024, activation='relu')(x)\n","# and a logistic layer -- we have 2 classes\n","predictions = Dense(2, activation='softmax')(x)\n","# this is the model we will train\n","model = Model(input=test.input, output=predictions)\n","model.summary()"],"execution_count":0,"outputs":[]}]}